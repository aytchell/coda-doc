<!doctype linuxdoc SYSTEM "../../dtd/linuxdoc.dtd" [

<!entity % latex "INCLUDE">
<!entity % html  "IGNORE">
<![ %latex; [ <!entity newpage PI "\newpage"> ]]>
<![ %html; [ <!entity newpage PI "<HR>"> ]]>
<!entity newpage PI "">
]>

<article>



<title> The Venus kernel interface
<author> Peter J. Braam
<date>v1.2, Mar 18, 1998

<abstract> This document describes the communication between Venus and
kernel level file system code needed for the operation of the Coda
filesystem.  This version document is meant to describe the current interface (version 1.0) as well as improvements we envisage.
</abstract>

<toc>
&newpage;<sect> Introduction <P> 

A key component in the Coda Distributed File System is the cache
manager, <em>Venus</em>.  

When processes on a Coda enabled system access files in the Coda
filesystem, requests are directed at the filesystem layer in the
operating system. The operating system will communicate with Venus to
service the request for the process.  Venus manages a persistent
client cache and makes remote procedure calls to Coda file servers and
related servers (such as authentication servers) to service these
requests it receives from the operating system.  When Venus has
serviced a request it replies to the operating system with appropiate
return codes, and other data related to the request.  Optionally the
kernel support for Coda may maintain a minicache of recently processed
requests to limit the number of interactions with Venus.  Venus
possesses the facility to inform the kernel when elements from its
minicache are no longer valid.

This document describes precisely this communication between the
kernel and Venus.  The definitions of so called upcalls and downcalls
will be given with the format of the data they handle. We shall also
describe the semantic invariants resulting from the calls.

Historically Coda was implemented in a BSD file system in Mach 2.6.
The interface between the kernel and Venus is very similar to the BSD
VFS interface.  Similar functionality is provided, and the format of
the parameters and returned data is very similar to the BSD VFS.  This
leads to an almost natural environment for implementing a kernel level
filesystem driver for Coda in a BSD system.  However, other operating
systems such as Linux and Windows 95 and NT have virtual filesystem
with different interfaces.

To implement Coda on these systems some reverse engineering of the
Venus/Kernel protocol is necessary.  Also it came to light that other
systems could profit significantly from certain small optimizations
and modifications to the protocol. To facilitate this work as well as
to make future ports easier, communication between Venus and the
kernel should be documented in great detail.  This is the aim of this
document.

&newpage;<sect> Servicing Coda filesystem calls <p> The service of a
request for a Coda file system service originates in a process <bf/P/
which accessing a Coda file. It makes a system call which traps to the
OS kernel. Examples of such calls trapping to the kernel are <em>read,
write, open, close, create, mkdir, rmdir, chmod</em> in a Unix
context.  Similar calls exist in the Win32 environment, and are named
<em>CreateFile, </em>.

Generally the operating system handles the request in a virtual
filesystem (VFS) layer, which is named I/O Manager in NT and IFS
manager in Windows 95.  The VFS is responsible for partial processing
of the request and for locating the specific filesystem(s) which will
service parts of the request.  Usually the information in the path
assists in locating the correct FS drivers.  Sometimes after extensive
pre-processing, the VFS starts invoking exported routines in the FS
driver.  This is the point where the FS specific processing of the
request starts, and here the Coda specific kernel code comes into
play.

The FS layer for Coda must expose and implement several interfaces.
First and foremost the VFS must be able to make all necessary calls to
the Coda FS layer, so the Coda FS driver must expose the VFS interface
as applicable in the operating system. These differ very significantly
among operating systems, but share features such as facilities to
read/write and create and remove objects.  The Coda FS layer services
such VFS requests in by invoking on or more well defined services
offered by the cache manager Venus.  When the replies from Venus have
come back to the FS driver, servicing of the VFS call continues and
finishes with a reply to the kernels VFS. Finally the VFS layer
returns to the process. 

As a result of this design a basic interface exposed by the FS driver
must allow Venus to manage message traffic.  In particular
Venus must be able to retrieve and place messages and to be notified
of the arrival of a new message. The notification must be through a
mechanism which does not block Venus since Venus must attend to
other tasks even when no messages are waiting or being processed.

<figure>
  <eps file="interfaces" height="7cm">
  <caption><label id="fig_overview">Interfaces of the Coda FS Driver
</figure>

Furthermore the FS layer provides for a special path of communication
between a user process and Venus, called the pioctl interface. The
pioctl interface is used for Coda specific services, such as
requesting detailed information about the persistent cache managed by
Venus. Here the involvement of the kernel is minimal.  It identifies
the calling process and passes the information on to Venus.  When
Venus replies the response is passed back to the caller in unmodified
form. 

Finally Venus allows the kernel FS driver to cache the results from
certain services.  This is done to avoid excessive context switches
and results in an efficient system.  However, Venus may acquire
information, for example from the network which implies that cached
information must be flushed or replaced. Venus then makes a downcall
to the Coda FS layer to request flushes or updates in the cache.  The
kernel FS driver handles such requests synchronously. 

Among these interfaces the VFS interface and the facility to place,
receive and be notified of messages are platform specific.  We will
not go into the calls exported to the VFS layer but we will state the
requirements of the message exchange mechanism. 

&newpage;<sect> The message layer <p>  

At the lowest level the communication between Venus and the FS driver
proceeds through messages.  The synchronization between processes
requesting Coda file service and Venus relies on blocking and waking
up processes.  The Coda FS driver processes VFS- and pioctl-requests
on behalf of a process P, creates messages for Venus, awaits replies
and finally returns to the caller.  The implementation of the exchange
of messages is platform specific, but the semantics have (so far)
appeared to be generally applicable.  Data buffers are created by the
FS Driver in kernel memory on behalf of P and copied to user memory in
Venus.

The FS Driver while servicing P makes <tt>upcall</tt>'s to Venus.
Such an upcall is dispatched to Venus by creating a message structure.
The structure contains the identification of P, the message sequence
number, the size of the request and a pointer to the data in kernel
memory for the request.  Since the data buffer is re-used to hold the
reply from Venus, there is a field for the size of the reply.  A flags
field is used in the message to precisely record the status of the
message.  Additional platform dependent structures involve pointers to
determine the position of the message on queues and pointers to
synchronization objects.  In the <tt/upcall/ routine the message
structure is filled in, flags are set to 0, and it is placed on the
<em>pending</em> queue.  The routine calling <tt/upcall/ is
responsible for allocating the data buffer; it's structure will be
described in the next section.

A facility must exist to notify Venus that the message has been
created, and implemented using available synchronization objects in
the OS. This notification is done in the <tt/upcall/ context of the
process P. When the message is on the pending queue, process P cannot
proceed in <tt/upcall/.  The (kernel mode) processing of P in the
filesystem request routine must be suspended until Venus has replied.
Therefore the calling thread in P is blocked in <tt/upcall/.  A
pointer in the message structure will locate the synchronization
object on which P is sleeping.

Venus detects the notification that a message has arrived, and the FS
driver allow Venus to retrieve the message with a
<tt>getmsg_from_kernel</tt> call. This action finishes in the kernel
by putting the message on the queue of processing messages and setting
flags to READ.  Venus is passed the contents of the data buffer. The
<tt/getmsg_from_kernel/ call now returns and Venus processes the
request.

At some later point the FS driver receives a message from Venus,
namely when Venus calls <tt>sendmsg_to_kernel</tt>.  At this moment
the Coda FS driver looks at the contents of the message and decides
if:

<itemize>

<item> the message is a reply for a suspended thread P.  If so it
removes the message from the processing queue and marks the message as
WRITTEN.  Finally, the FS driver unblocks P (still in the kernel mode
context of Venus) and the <tt>sendmsg_to_kernel</tt> call returns to
Venus.  The process P will be scheduled at some point and continues
processing its <tt/upcall/ with the data buffer replaced with the
reply from Venus.

<item> The message is a <em>downcall</em>.  A downcall is a request
from Venus to the FS Driver. The FS driver processes the request
immediately (usually a cache eviction or replacement) and when finishes
<tt/sendmsg_to_kernel/ returns.
</itemize>

Now P awakes and continues processing <tt/upcall/.  There are some
subtleties to take account off. First P will determine if it was woken
up in <tt/upcall/ by a signal from some other source (for example an
attempt to terminate P) or as is normally the case by Venus in its
<tt/sendmsg_to_kernel/ call.  In the normal case, the upcall routine
will deallocate message structure and return.  The FS routine can
proceed with its processing.


<figure>
  <eps file="sleep">
  <caption><label id="ServerOrg"> Sleeping and IPC arrangements
</figure>

In case P is woken up by a signal and not by Venus, it will first look
at the flags field.  If the message is not yet READ, the process P can
handle it's signal without notifying Venus.  If Venus has READ, and
the request should not be processed, P can send Venus a signal message
to indicate that it should disregard the previous message.  Such
signals are put in the queue at the head, and read first by Venus.  If
the message is already marked as WRITTEN it is too late to stop the
processing.  The VFS routine will now continue. <footnote/If a VFS
request involves more than one upcall, this can lead to complicated
state, an extra field "handle_signals" could be added in the message
structure to indicate points of no return have been passed./


<sect1> Implementation details <p>
The Unix implementation of this mechanism has been through the
implemenation of a character device associated with Coda.  Venus
retrieves messages by doing a <tt/read/ on the device, replies are
sent with a <tt/write/ and notification is through the <tt/select/
system call on the file descriptor for the device.  The process P is
kept waiting on an interruptible wait queue object.

In Windows NT and the DPMI Windows 95 implementation a DeviceIoControl
call is used.  The DeviceIoControl call is designed to copy buffers
from user memory to kernel memory with OPCODES. The
<tt/sendmsg_to_kernel/ is issued as a synchronous call, while the
<tt/getmsg_from_kernel/ call is asynchrounous.  Windows EventObjects
are used for notification of message arrival.  The process P is kept
waiting on a KernelEvent object in NT and a semaphore in Windows 95. 

&newpage;<sect> The interface at the call level <p>

This section describes the upcalls a Coda FS driver can make to Venus.
Each of these upcalls make use of three structures: <tt>
inputArgs</tt> for communication from kernel to Venus, and
<tt/outputArgs/ back from Venus to the kernel and finally downcalls
which are calls from Venus to the kernel initiated by Venus.  

<verb>
union inputArgs {
    struct cfs_in_hdr ih;	/* NB: every struct below begins with an ih */
    struct cfs_open_in cfs_open;
    struct cfs_close_in cfs_close;
    struct cfs_ioctl_in cfs_ioctl;
    struct cfs_getattr_in cfs_getattr;
    struct cfs_setattr_in cfs_setattr;
    struct cfs_access_in cfs_access;
    struct cfs_lookup_in cfs_lookup;
    struct cfs_create_in cfs_create;
    struct cfs_remove_in cfs_remove;
    struct cfs_link_in cfs_link;
    struct cfs_rename_in cfs_rename;
    struct cfs_mkdir_in cfs_mkdir;
    struct cfs_rmdir_in cfs_rmdir;
    struct cfs_readdir_in cfs_readdir;
    struct cfs_symlink_in cfs_symlink;
    struct cfs_readlink_in cfs_readlink;
    struct cfs_fsync_in cfs_fsync;
    struct cfs_inactive_in cfs_inactive;
    struct cfs_vget_in cfs_vget;
    struct cfs_rdwr_in cfs_rdwr;
    struct cfs_open_by_path_in cfs_open_by_path;
};
</verb>

<verb>
union outputArgs {
    struct cfs_out_hdr oh; /* NB: every struct below begins with an oh */
    struct cfs_root_out cfs_root;
    struct cfs_open_out cfs_open;
    struct cfs_ioctl_out cfs_ioctl;
    struct cfs_getattr_out cfs_getattr;
    struct cfs_lookup_out cfs_lookup;
    struct cfs_create_out cfs_create;
    struct cfs_mkdir_out cfs_mkdir;
    struct cfs_readdir_out cfs_readdir;
    struct cfs_readlink_out cfs_readlink;
    struct cfs_vget_out cfs_vget;
    struct cfs_purgeuser_out cfs_purgeuser;
    struct cfs_zapfile_out cfs_zapfile;
    struct cfs_zapdir_out cfs_zapdir;
    struct cfs_zapvnode_out cfs_zapvnode;
    struct cfs_purgefid_out cfs_purgefid;
    struct cfs_rdwr_out cfs_rdwr;
    struct cfs_replace_out cfs_replace;
    struct cfs_open_by_path_out cfs_open_by_path;
};
</verb>

<verb>
union cfs_downcalls {
    /* CFS_FLUSH  is also a down call */
    struct cfs_purgeuser_out purgeuser;
    struct cfs_zapfile_out zapfile;
    struct cfs_zapdir_out zapdir;
    struct cfs_zapvnode_out zapvnode;
    struct cfs_purgefid_out purgefid;
    struct cfs_replace_out replace;
};

</verb>

The headers are common to all calls and contain process, authentication and opcode information:

<verb>
struct cfs_in_hdr {
    unsigned long opcode;
    unsigned long unique;    /* Keep multiple outstanding msgs distinct */
    u_short pid;		  /* Common to all */
    u_short pgid;		  /* Common to all */
    u_short sid;                  /* to become the PAG */
    struct coda_cred cred;	  /* to become a PAG */
};

/* Really important that opcode and unique are 1st two fields! */
struct cfs_out_hdr {
    unsigned long opcode;
    unsigned long unique;	
    unsigned long result;
};
</verb>

Before going on let us elucidate the role of the various fields. The
inputArgs start with the <tt/opcode/ which defines the type of service
requested from Venus. There are approximately 30 upcalls at present
which we will discuss.   The <tt/unique/ field labels the inputArg
with unique number which will identify the message uniquely.  A
process and process group id are passed.  Finally the credentials of
the caller are included.  

Before delving into the specific calls we need to discuss a variety of
data structures shared by the kernel and Venus.

<sect1> Data structures shared by the kernel and Venus <p>

The <tt/CodaCred/ structure defines a variety of user and group id's as
they are set for the calling process. The <tt/vuid_t/ and <tt/guid_t/
are 32 bit unsigned integers.  It also defines group member
ship in an array.  On Unix the CodaCred has proven sufficient to
implement good security semantics for Coda but the structure may have
to undergo modification for the Windows environment when these mature.
<verb>
struct CodaCred {
    vuid_t cr_uid, cr_euid, cr_suid, cr_fsuid; /* Real, efftve, set, fs uid*/
    vgid_t cr_gid, cr_egid, cr_sgid, cr_fsgid; /* same for groups */
    vgid_t cr_groups[NGROUPS];	      /* Group membership for caller */
};
</verb>

<bf/NOTE/ It is questionable if we need CodaCreds in Venus. Finally
Venus doesn't know about groups, although it does create files with
the default uid/gid.  Perhaps the list of group membership is
superfluous. 


The next item is the fundamental identifier used to identify Coda
files, the <tt/ViceFid/.  A fid of a file uniquely defines a file or
directory in the Coda filesystem within a <em>cell</em>.  <footnote>A
<em>cell</em> is a group of Coda servers acting under the aegis of a
single system control machine or SCM. See the Coda Administration
manual for a detailed description of the role of the SCM.</footnote>

<verb>
typedef struct ViceFid {
    VolumeId Volume;
    VnodeId Vnode;
    Unique_t Unique;
} ViceFid;
</verb>

Each of the constituent fields: <tt/VolumeId, VnodeId/ and
<tt/Unique_t/ are unsigned 32 bit integers.  We envisage that a
further field will need to be prefixed to identify the Coda cell; this
will probably take the form of a Ipv6 size IP address naming the Coda
cell through DNS.  

The next important structure shared between Venus and the kernel are
the attributes of the file.  The following structure is used to
exchange information.  It has room for future extensions such as
support for device files (currently not present in Coda). 

<verb>
struct coda_vattr {
	enum coda_vtype	va_type;	/* vnode type (for create) */
	u_short		va_mode;	/* files access mode and type */
	short		va_nlink;	/* number of references to file */
	vuid_t		va_uid;		/* owner user id */
	vgid_t		va_gid;		/* owner group id */
	long		va_fsid;	/* file system id (dev for now) */
	long		va_fileid;	/* file id */
	u_quad_t	va_size;	/* file size in bytes */
	long		va_blocksize;	/* blocksize preferred for i/o */
	struct timespec	va_atime;	/* time of last access */
	struct timespec	va_mtime;	/* time of last modification */
	struct timespec	va_ctime;	/* time file changed */
	u_long		va_gen;		/* generation number of file */
	u_long		va_flags;	/* flags defined for file */
	dev_t		va_rdev;	/* device special file represents */
	u_quad_t	va_bytes;	/* bytes of disk space held by file */
	u_quad_t	va_filerev;	/* file modification number */
	u_int		va_vaflags;	/* operations flags, see below */
	long		va_spare;	/* remain quad aligned */
};
</verb>

<sect1> The pioctl interface <p>

Coda specific requests can be made by application through the pioctl
interface. The pioctl is implemented as an ordinary ioctl on a
ficticious file <tt>/coda/.CONTROL</tt>.  The piocl call opens this
file, gets a file handle and makes the ioctl call. Finally it closes
the file. 

The kernel involvement in this is limited to providing the facility to
open and close and pass the ioctl message <em/and/ to verify that a
path in the pioctl data buffers is a file in a Coda filesystem.

The kernel is handed a data packet of the form:
<verb>
    struct {
	const char *path;
	struct ViceIoctl vidata;
	int follow;
    } data;
</verb>

where

<verb>
struct ViceIoctl {
	caddr_t in, out;	/* Data to be transferred in, or out */
	short in_size;		/* Size of input buffer <= 2K */
	short out_size;		/* Maximum size of output buffer, <= 2K */
};
</verb>

The <tt/path/ must be a Coda file, otherwise the <tt/ioctl/ upcall
will not be made. 

<bf/NOTE/  The data structures and code are a mess.  We need to clean
this up. 

We now proceed to document the individual calls:

&newpage;<sect1>root<p>

<bf>Arguments</bf>
<descrip>
<tag/in/ empty
<tag/out/ 
<verb>
	struct cfs_root_out {
	    ViceFid VFid;
	} cfs_root;
</verb>
</descrip>

<bf/Description/ This call is made to Venus during the initialization
of the Coda filesystem. If the <tt/result/ is zero, the <tt/cfs_root/
structure contains the ViceFid of the root of the Coda filesystem. If
a non-zero result is generated, its value is a platform dependent
error code indicating the difficulty Venus encountered in locating the
root of the Coda filesystem.

&newpage;<sect1>lookup<p>

<bf/Summary/ Find the ViceFid and type of an object in a directory if
it exists.

<bf>Arguments</bf>
<descrip>
<tag/in/ 
<verb>
	struct  cfs_lookup_in {
	    ViceFid	VFid;
	    char        *name;		/* Place holder for data. */
	} cfs_lookup;
</verb>
<tag/out/ 
<verb>
	struct cfs_lookup_out {
	    ViceFid VFid;
	    int	vtype;
	} cfs_lookup;
</verb>
</descrip>

<bf/Description/ This call is made to determine the ViceFid and
filetype of a directory entry.  The directory entry requested carries
name <tt/name/ and Venus will search the directory identified by
<tt/cfs_lookup_in.VFid/.  The <tt/result/ may indicate that the name
does not exist, or that difficulty was encountered in finding it
(e.g. due to disconnection).  If the <tt/result/ is zero, the field
<tt/cfs_lookup_out.VFid/ contains the targets ViceFid and
<tt/cfs_lookup_out.vtype/ the <tt/coda_vtype/ giving the type of
object the name designates. 

The name of the object is an 8 bit character string of maximum length
CFS_MAXNAMLEN, currently set to 256 (including a 0 terminator.)

It is extremely important to realize that Venus bitwise or's the field
<tt/cfs_lookup.vtype/ with <tt/CFS_NOCACHE/ to indicate that the
object should not be put in the kernel name cache. Files in conflict or 
uncovered mountpoints should never be cached by the kernel and each lookup
should make it to Venus.

<bf/NOTE/ The type of the vtype is currently wrong.  It should be
<tt/coda_vtype/. Linux does not take note of <tt/CFS_NOCACHE/.  It
should. 

&newpage;<sect1>getattr<p>

<bf>Summary</bf> Get the attributes of a file.

<bf>Arguments</bf>
<descrip>
<tag/in/ 
<verb>
	struct cfs_getattr_in {
	    ViceFid VFid;
	    struct coda_vattr attr; /* XXXXX */
	} cfs_getattr;
</verb>
<tag/out/ 
<verb>
	struct cfs_getattr_out {
	    struct coda_vattr attr;
	} cfs_getattr;
</verb>
</descrip>

<bf/Description/
This call returns the attributes of the file identified by fid. 

<bf/Errors/ Errors can occur if the object with fid does not exist,
are unaccessible or if the caller does not have permission to fetch
attributes.

<bf/Note/ Many kernel FS drivers (Linux, NT and Windows 95 need to
acquire the attributes as well as the Fid for the instantiation of an
internal "inode" or "FileHandle".  A significant improvement in
performance on such systems could be made by combining the <em/lookup/
and <em/getattr/ calls both at the Venus/kernel interaction level and
at the RPC level. 

The <tt/vattr/ structure included in the input arguments is
superfluous and should be removed.

&newpage;<sect1>setattr<p>

<bf/Summary/ Set the attributes of a file.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_setattr_in {
	    ViceFid VFid;
	    struct coda_vattr attr;
	} cfs_setattr;
</verb>
<tag/out/ empty
</descrip>

<bf/Description/ The structure <tt/attr/ is filled with attributes to
be changed in BSD style.  Attributes not to be changed are set to -1,
apart from <tt/vtype/ which is set to <tt/VNON/. Other are set to the
value to be assigned.  The only attributes which the FS driver may
request to change are the mode, ownner, groupid, atime, mtime and
ctime.  The return value indicates success or failure.

<bf/Errors/ A variety of errors can occur.  The object may not exist,
may be inaccessible, or permission may not be granted by Venus.

&newpage;<sect1>access<p>

<bf/Summary/

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_access_in {
	    ViceFid	VFid;
	    int	flags;
	} cfs_access;
</verb>
<tag/out/ empty
</descrip>

<bf/Description/ Verify if access to the object identified by <tt/VFid/ for
operations described by <tt/flags/ is permitted.  The result indicates
if access will be granted.  It is important to remember that Coda uses
ACL's to enforce protection and that ultimately the servers, not the
clients enforce the security of the system.  The result of this call
will depend on wether a <em/token/ is held by the user.

<bf/Errors/ The object may not exist, or the ACL describing the
protection may not be accessible.

&newpage;<sect1>create<p>

<bf/Summary/ Invoked to create a file

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_create_in {
	    ViceFid VFid;
	    struct coda_vattr attr;
	    int excl;
	    int mode;
	    char	*name;		/* Place holder for data. */
	} cfs_create;
</verb>
<tag/out/
<verb>
	struct cfs_create_out {
	    ViceFid VFid;
	    struct coda_vattr attr;
	} cfs_create;

</verb>
</descrip>

<bf/Description/  This upcall is invoked to request creation of a
file.  The file will be created in the directory identified by
<tt/VFid/, its name will be <tt/name/, and the mode will be
<tt/mode/.  If <tt/excl/ is set an error will be returned if the file
already exists.  If the size field in attr is set to zero the file
will be truncated.  The uid and gid of the file are set by converting
the CodaCred to a uid using a macro <tt/CRTOUID/ (this macro is
platform dependent).  Upon success the VFid and attributes of the file
are returned.  The Coda FS Driver will normally instantiate a vnode,
inode or filehandle at kernel level for the new object. 


<bf/Errors/ A variety of errors can occur. Permissions may be
insufficient. If the object exists and is not a file the error
<tt/EISDIR/ is returned under Unix.

<bf/NOTE/ The packing of parameters is very inefficient and appears to
indicate confusion between the system call creat and the VFS operation
create. The VFS operation create is only called to create new
objects. This create call differs from the Unix one in that it is not
invoked to return a file descriptor. The trunctate and exclusive
options, together with the mode, could simply be part of the mode as
it is under Unix.  There should be no flags argument; this is used in
<tt/open/ (2) to return a filedescriptor for READ or WRITE mode.

The attributes of the directory should be returned too, since the size
and mtime changed.

&newpage;<sect1>mkdir<p>

<bf/Summary/ Create a new directory.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_mkdir_in {
	    ViceFid	VFid;
	    struct coda_vattr attr;
	    char	*name;		/* Place holder for data. */
	} cfs_mkdir;
</verb>
<tag/out/
<verb>
	struct cfs_mkdir_out {
	    ViceFid VFid;
	    struct coda_vattr attr;
	} cfs_mkdir;
</verb>
</descrip>

<bf/Description/ This call is similar to <tt/create/ but creates a
directory. Only the <tt/mode/ field in the input parameters is used
for creation.  Upon successful creation, the <tt/attr/ returned
contains the attributes of the new directory.  

<bf/Errors/ As for create.

<bf/NOTE/ The input parameter should be changed to <tt/mode/ instead
of attributes. 

The attributes of the parent should be returned since the size and
mtime changes.

&newpage;<sect1>link<p>

<bf/Summary/ Create a link to an existing file.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_link_in {
	    ViceFid sourceFid;          /* cnode to link *to* */
	    ViceFid destFid;            /* Directory in which to place link */
	    char	*tname;		/* Place holder for data. */
	} cfs_link;
</verb>
<tag/out/ empty
</descrip>

<bf/Description/ This call creates a link to the <tt/sourceFid/ in the
directory identified by <tt/destFid/ with name <tt/tname/.  The source
must reside in the targets parent, i.e. the source must be have parent
<tt/destFid/, i.e. Coda does not support cross directory hard links.
Only the return value is relevant.  It indicates success or the type
of failure.

<bf/Errors/ The usual errors can occur.
&newpage;<sect1>symlink<p>

<bf/Summary/ create a symbolic link

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_symlink_in {
	    ViceFid	VFid;          /* Directory to put symlink in */
	    char	*srcname;
	    struct coda_vattr attr;
	    char	*tname;
	} cfs_symlink;
</verb>
<tag/out/ none
</descrip>

<bf/Description/ Create a symbolic link. The link is to be placed in
the directory identified by <tt/VFid/ and named <tt/tname/.  It should
point to the pathname <tt/srcname/.  The attributes of the newly
created object are to be set to <tt/attr/.

<bf/Errors/

<bf/NOTE/ The attributes of the target directory should be returned
since its size changed. 

&newpage;<sect1>remove<p>

<bf/Summary/ Remove a file

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_remove_in {
	    ViceFid	VFid;
	    char	*name;		/* Place holder for data. */
	} cfs_remove;
</verb>
<tag/out/ none
</descrip>

<bf/Description/  Remove file named <tt/cfs_remove_in.name/ in
directory identified by   <tt/VFid/. 

<bf/Errors/

<bf/NOTE/ The attributes of the directory should be returned since its
mtime and size may change.

&newpage;<sect1>rmdir<p>

<bf/Summary/ Remove a directory

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_rmdir_in {
	    ViceFid	VFid;
	    char	*name;		/* Place holder for data. */
	} cfs_rmdir;
</verb>
<tag/out/ none
</descrip>

<bf/Description/ Remove the directory with name <tt/name/ from the
directory identified by <tt/VFid/.

<bf/Errors/

<bf/NOTE/ The attributes of the parent directory should be returned
since its mtime and size may change. 

&newpage;<sect1>readlink<p>

<bf/Summary/ Read the value of a symbolic link.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_readlink_in {
	    ViceFid VFid;
	} cfs_readlink;
</verb>
<tag/out/
<verb>
	struct cfs_readlink_out {
	    int	count;
	    caddr_t	data;		/* Place holder for data. */
	} cfs_readlink;
</verb>
</descrip>

<bf/Description/ This routine reads the contents of symbolic link
identified by <tt/VFid/ into the buffer <tt/data/.  The buffer
<tt/data/ must be able to hold any name up to <tt/CFS_MAXNAMLEN/ (PATH or
NAM??). 

<bf/Errors/ No unusual errors.

&newpage;<sect1>open<p>

<bf/Summary/ Open a file.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_open_in {
	    ViceFid	VFid;
	    int	flags;
	} cfs_open;
</verb>
<tag/out/
<verb>
	struct cfs_open_out {
	    dev_t	dev;
	    ino_t	inode;
	} cfs_open;
</verb>
</descrip>

<bf/Description/  This request asks Venus to place the file identified
by <tt/VFid/ in its cache and to note that the calling process wishes
to open it with <tt/flags/ as in <tt/open(2)/.  The return value to
the kernel differs for Unix and Windows systems.  For Unix systems the
Coda FS Driver is informed of the device and inode number of the
container file in the fields <tt/dev/ and <tt/inode/.  For Windows the
path of the container file is returned to the kernel. 

<bf/Errors/

<bf/NOTE/ Currently the <tt/cfs_open_out/ structure is not properly
adapted to deal with the windows case.  It might be best to implement
two upcalls, one to open aiming at a container file name, the other at
a container file inode. 

&newpage;<sect1>close<p>

<bf/Summary/ Close a file, update it on the servers.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_close_in {
	    ViceFid	VFid;
	    int	flags;
	} cfs_close;
</verb>
<tag/out/ none
</descrip>

<bf/Description/ Close the file identified by <tt/VFid/.  

<bf/Errors/

<bf/NOTE/ The <tt/flags/ argument is bogus and not used.  However,
Venus' code has room to deal with an <tt/execp/ input field, probably
this field should be used to inform Venus that the file was closed but
is still memory mapped for execution.  There are comments about
fetching versus not fetching the data in Venus <tt/vproc_vfscalls/.
This seems silly.  If a file is being closed, the data in the
container file is to be the new data.  Here again the <tt/execp/ flag
might be in play to create confusion: presently Venus might think a
file can be flushed from the cache when it is still memory mapped.
This needs to be understood.

&newpage;<sect1>ioctl<p>

<bf/Summary/ Do an ioctl on a file. This includes the piocl interface.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_ioctl_in {
	    ViceFid VFid;
	    int	cmd;
	    int	len;
	    int	rwflag;
	    char *data;			/* Place holder for data. */
	} cfs_ioctl;
</verb>
<tag/out/
<verb>
	struct cfs_ioctl_out {
	    int	len;
	    caddr_t	data;		/* Place holder for data. */
	} cfs_ioctl;
</verb>
</descrip>

<bf/Description/ Do an ioctl operation on a file.  The <tt/command,
len/ and <tt/data/ arguments are filled as usual.  <tt/flags/ is not
used by Venus. 

<bf/Errors/

<bf/NOTE/ Another bogus parameter.  <tt/flags/ is not used.  What is
the business about PREFETCHING in the Venus' code?


&newpage;<sect1>rename<p>

<bf/Summary/ Rename a fid.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_rename_in {
	    ViceFid	sourceFid;
	    char	*srcname;
	    ViceFid destFid;
	    char	*destname;
	} cfs_rename;

</verb>
<tag/out/ none
</descrip>

<bf/Description/  Rename the object with name <tt/srcname/ in
directory <tt/sourceFid/ to <tt/destname/ in <tt/destFid/.   It is
important that the names <tt/srcname/ and <tt/destname/ are 0
terminated strings.  Strings in Unix kernels are not always null
terminated. 

<bf/Errors/

&newpage;<sect1>readdir<p>

<bf/Summary/ Read directory entries.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_readdir_in {
	    ViceFid	VFid;
	    int	count;
	    int	offset;
	} cfs_readdir;
</verb>
<tag/out/
<verb>
	struct cfs_readdir_out {
	    int	size;
	    caddr_t	data;		/* Place holder for data. */
	} cfs_readdir;
</verb>
</descrip>

<bf/Description/ Read directory entries from <tt/VFid/ starting at
<tt/offset/ and read at most <tt/count/ bytes.  Returns the data
into <tt/data/ and indicates the size returned <tt/size/.

<bf/Errors/

<bf/NOTE/ This call is not used.  Readdir operations exploit container
files.  We will re-evaluate this during the directory revamp which is
about to take place. 

&newpage;<sect1>vget<p>

<bf/Summary/ instructs Venus to do an <tt/FSDB->Get/.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_vget_in {
	    ViceFid VFid;
	} cfs_vget;
</verb>
<tag/out/
<verb>
	struct cfs_vget_out {
	    ViceFid VFid;
	    int	vtype;
	} cfs_vget;
</verb>
</descrip>

<bf/Description/ This upcall asks Venus to do a <tt/get/ operation on
an <tt/fsobj/ labelled by <tt/VFid/. 

<bf/Errors/

<bf/NOTE/ This operation is not used.  However, it is extremely useful
since it can be used to deal with read/write memory mapped files.
These can be "pinned" in the Venus cache using <tt/vget/ and release
with <tt/inactive/.

&newpage;<sect1>fsync<p>

<bf/Summary/ Tell Venus to update the RVM attributes of a file. 

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_fsync_in {
	    ViceFid VFid;
	} cfs_fsync;
</verb>
<tag/out/ none
</descrip>

<bf/Description/  Ask Venus to update RVM attributes of object
<tt/VFid/. This should be called as  part of kernel level <tt/fsync/
type calls.  The <tt/result/ indicates if the synching was
successful. 

<bf/Errors/

<bf/NOTE/ Linux does not implement this call. It should. 

&newpage;<sect1>inactive<p>

<bf/Summary/ Tell Venus a vnode is no longer in use. 

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_inactive_in {
	    ViceFid VFid;
	} cfs_inactive;
</verb>
<tag/out/ none
</descrip>

<bf/Description/ This operation returns <tt/EOPNOTSUPP/.  

<bf/Errors/

<bf/NOTE/ This should perhaps be removed. 

&newpage;<sect1>rdwr<p>

<bf/Summary/ Read or write from a file

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct cfs_rdwr_in {
	    ViceFid	VFid;
	    int	rwflag;
	    int	count;
	    int	offset;
	    int	ioflag;
	    caddr_t	data;		/* Place holder for data. */	
	} cfs_rdwr;
</verb>
<tag/out/
<verb>
	struct cfs_rdwr_out {
	    int	rwflag;
	    int	count;
	    caddr_t	data;	/* Place holder for data. */
	} cfs_rdwr;
</verb>
</descrip>

<bf/Description/ This upcall asks Venus to read or write from a file.

<bf/Errors/

<bf/NOTE/ It should be removed since it is against the Coda philosophy that
read/write operations never reach Venus.  I have been told the
operation does not work.  It is not currently used.


&newpage;<sect1>odymount<p>

<bf/Summary/ Allows mounting multiple Coda "filesystems" on one Unix mount
point.

<bf/Arguments/
<descrip>
<tag/in/
<verb>
	struct ody_mount_in {
	    char	*name;		/* Place holder for data. */
	} ody_mount;
</verb>
<tag/out/
<verb>
	struct ody_mount_out {
	    ViceFid VFid;
	} ody_mount;
</verb>
</descrip>

<bf/Description/  Asks Venus to return the rootfid of a Coda system
named <tt/name/.  The fid is returned in <tt/VFid/. 

<bf/Errors/

<bf/NOTE/ This call was used by David for dynamic sets.  It should be
removed since it causes a jungle of pointers in the VFS mounting area.
It is not used by Coda proper.  Call is not implemented by Venus. 

&newpage;<sect1>ody_lookup<p>

<bf/Summary/ Looks up something. 

<bf/Arguments/
<descrip>
<tag/in/ irrelevant
<tag/out/ irrelevant
</descrip>

<bf/Description/

<bf/Errors/

<bf/NOTE/ Gut it. Call is not implemented by Venus. 

&newpage;<sect1>ody_expand<p>

<bf/Summary/ expands something in a dynamic set.

<bf/Arguments/
<descrip>
<tag/in/ irrelevant
<tag/out/ irrelevant
</descrip>

<bf/Description/

<bf/Errors/

<bf/NOTE/ Gut it.  Call is not implemented by Venus. 

&newpage;<sect1>prefetch<p>

<bf/Summary/ Prefetch a dynamic set.

<bf/Arguments/
<descrip>
<tag/in/ Not documented.
<tag/out/ Not documented.
</descrip>

<bf/Description/  Venus worker.cc has support for this call, although
it is noted that it doesn't work.  Not surprising, since the kernel
does not have support for it. (ODY_PREFETCH is not a defined
operation). 

<bf/Errors/

<bf/NOTE/ Gut it. It isn't working and isn't used by Coda. 


&newpage;<sect1>signal<p>

<bf/Summary/ Send Venus a signal about an upcall. 

<bf/Arguments/
<descrip>
<tag/in/ none
<tag/out/ not applicable.
</descrip>

<bf/Description/  This is an out-of-band upcall to Venus to inform
Venus that the calling process received a signal after Venus read the
message from the input queue.  Venus is supposed to clean up the
operation.  

<bf/Errors/ No reply is given.

<bf/NOTE/ We need to better understand what Venus needs to clean up
and if it is doing this correctly.  Also we need to handle multiple
upcall per system call situations correctly.  It would be important to
know what state changes in Venus take place after an upcall for which
the kernel is responsible for notifying Venus to clean up (e.g. open
definitely is such a state change, but many others are maybe not). 

&newpage;<sect> The minicache and downcalls <p>

The Coda FS Driver can cache results of <tt/lookup/ and <tt/access/
upcalls, to limit the frequency of upcalls.  Upcalls carry a price
since a process context switch needs to take place.  The counterpart
of caching the information is that Venus will notify the FS Driver
that cached entries must be flushed or renamed.

The kernel code generally has to maintain a structure which links the
internal file handles (called vnodes in BSD, inodes in Linux and
FileHandles in Windows) with the ViceFid's which Venus maintains.
The reason is that frequent translations back and forth are needed in
order to make upcalls and use the results of upcalls.  Such linking
objects are called <bf/cnodes/.

The current minicache implementations have cache entries which record
the following:
<enum>
<item> the name of the file
<item> the cnode of the directory containing the object
<item> a list of CodaCred's for which the lookup is permitted.
<item> the cnode of the object
</enum>

The <tt/lookup/ call in the Coda FS Driver may request the cnode of
the desired object from the cache, by passing it's name, directory and
the CodaCred's of the caller.  The cache will return the cnode or
indicate that it cannot be found.  The Coda FS Driver must be careful
to invalidate cache entries when it modifies or removes objects.

When Venus obtains information that indicates that cache entries are
no longer valid, it will make a downcall to the kernel.  Downcalls are
intercepted by the Coda FS Driver and lead to cache invalidations of
the kind described below.  The Coda FS Driver does not return an error
unless the downcall data could not be read into kernel memory. 

<sect1>INVALIDATE<p>

No information is available on this call. 

<sect1>FLUSH<p>

<bf/Arguments/ None
 
<bf/Summary/ Flush the name cache entirely.

<bf/Description/ Venus issues this call upon startup and when it
dies. This is to prevent stale cache information being held.  Some
operating systems allow the kernel name cache to be switched off
dynamically. When this is done, this downcall is made. 

<sect1> PURGEUSER<p>

<bf/Arguments/
<verb>
	struct cfs_purgeuser_out {/* CFS_PURGEUSER is a venus->kernel call */
	    struct CodaCred cred;
	} cfs_purgeuser;
</verb>

<bf/Description/ Remove all entries in the cache carrying the Cred.
This call is issued when tokes for a user expire or are flushed.

<sect1>ZAPFILE<p>

<bf/Arguments/
<verb>
	struct cfs_zapfile_out {  /* CFS_ZAPFILE is a venus->kernel call */
	    ViceFid CodaFid;
	} cfs_zapfile;
</verb>

<bf/Description/ Remove all entries which have the (dir vnode, name)
pair. This is issued as a result of an invalidation of cached
attributes of a vnode.

<bf/NOTE/ Call is not named correctly in NetBSD and Mach. 
The minicache <tt/zapfile/ routine takes different arguments. Linux
does not implement the invalidation of attributes correctly. 


<sect1>ZAPDIR<p>

<bf/Arguments/
<verb>
	struct cfs_zapdir_out {	  /* CFS_ZAPDIR is a venus->kernel call */
	    ViceFid CodaFid;
	} cfs_zapdir;
</verb>

<bf/Description/ Remove all entries in the cache lying in a directory
<tt/CodaFid/, and all children of this directory. This call is issed
when Venus receives a callback on the directory.

<sect1>ZAPVNODE<p>

<bf/Arguments/
<verb>
	struct cfs_zapvnode_out { /* CFS_ZAPVNODE is a venus->kernel call */
	    struct CodaCred cred;
	    ViceFid VFid;
	} cfs_zapvnode;
</verb>

<bf/Description/ Remove all entries in the cache carrying the <tt/cred/ and
<tt/VFid/ as in the arguments. This downcall is probably never
issued. 

<sect1>PURGEFID<p>

<bf/Summary/

<bf/Arguments/
<verb>
	struct cfs_purgefid_out { /* CFS_PURGEFID is a venus->kernel call */
	    ViceFid CodaFid;
	} cfs_purgefid;
</verb>

<bf/Description/ Flush the attribute for the file. If it is a dir (odd
vnode), purge its children from the namecache remove the file from the
namecache.


<sect1>REPLACE<p>

<bf/Summary/ Replace the Fid's for a collection of names.

<bf/Arguments/
<verb>
	struct cfs_replace_out { /* cfs_replace is a venus->kernel call */
	    ViceFid NewFid;
	    ViceFid OldFid;
	} cfs_replace;
</verb>

<bf/Description/ This routine replaces a ViceFid in the name cache
with another.  It is added to allow Venus during reintegration to
replace locally allocated temp fids while disconnected with global
fids even when the reference count on those fids are not zero.

&newpage;<sect> Initialization and cleanup <p>

This section gives brief hints as to desirable features for the Coda
FS Driver at startup and upon shutdown or Venus failures.  Before
entering the discussion it is useful to repeat that the Coda FS Driver
maintains the following data:

<enum>
<item> message queues
<item> cnodes
<item> name cache entries
</enum>
The name cache entries are entirely private to the driver, so they can
easily be manipulated.   The message queues will generally have clear
points of initialization and destruction.  The cnodes are much more
delicate.  User processes hold reference counts in Coda filesystems
and it can be difficult to clean up the cnodes.

It can expect requests through:
<enum>
<item> the message subsystem
<item> the VFS layer
<item> pioctl interface
</enum>
Currently the <em/pioctl/ passes through the VFS for Coda so we can
treat these similarly. 

<sect1> Requirements <p>

The following requirements should be accomodated:
<enum>
<item> The message queueus should have <tt/open/ and <tt/close/
routines.  On Unix the opening of the character devices are such
routines.  
  <itemize> 
  <item> Before opening, no messages can be placed. 
  <item> Opening will
  remove any old messages still pending.  
  <item> Close will notify any sleeping
  processes that their upcall cannot be completed. 
  <item> Close will free all
  memory allocated by the message queues.
  </itemize>

<item> At open the namecache shall be initialized to empty state. 

<item> Before the message queues are open, all VFS operations will
fail. Fortunately this can be achieved by making sure than mounting
the Coda filesystem cannot succeed before opening.

<item> After closing of the queues, no VFS operations can succeed.
Here one needs to be careful, since a few operations (lookup,
read/write, readdir) can proceed without upcalls.  These must be
explicitly blocked. 

<item> Upon closing the namecache shall be flushed and disabled.

<item> All memory held by cnodes can be freed without relying on
upcalls. 

<item> Unmounting the file system can be done without relying on
upcalss. 

<item> Mounting the Coda filesystem should fail gracefully if Venus
cannot get the <tt/rootfid/ or the attributes of the <tt/rootfid/.
The latter is best implemented by Venus fetching these objects before
attempting to mount. 

</enum>

<bf/NOTE/  NetBSD in particular but also Linux have not implemented
the above requirements fully.  For smooth operation this needs to be
corrected. 

&newpage;<sect> Inode numbers <p>

The Unix stat system call returns inode numbers for files.  These
should be correct for Coda files for library calls like getwd and tar
to function correctly.

The mount points of volumes complicate the values which Venus assigns to the inode numbers in the statbuf structure.  The rules are as follows:

<enum>
<item> A fid is converted to an integer (vol<<20) + (vnode<<10) + (uniq).
<item> If a fid is the root of a volume, then it is assigned the inode number of the symlink which is its mountpoint. 
</enum>

The kernel should never cache the symlink mountpoints but may see them
in case they cannot be covered. Also downcalls are made to purge the
symlink fid from the cache, despite the fact that the kernel has never
seen the mountpoint fid before.

Kernel code for Coda will need to implement a lookup mechanism to find
vnodes (BSD) inodes (Linux) or FileHandles (Win) based on Fid, and it
will need to be careful to get things right for volume roots.

</article>
