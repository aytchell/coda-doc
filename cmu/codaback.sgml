<!doctype linuxdoc system [
]>

<article>
<title>Coda Backup System
<author> Peter J. Braam
<date> March 1998
<abstract>
This is a short descritpion of the backup system from a technical perspective.
</abstract

<sect>
Introduction<p>

The Coda backup sytem falls into two components:

<item>The backup.cc program, which clones and dumps volumes. It works over the network and full and incremental dumps are supported.

Writing and retrieving such dumps to and from tapes.

Merging incremental and full dumps.

Restoring dumps.
</sect>


<sect>Backup Program<p>

This program takes involved important parameters and config. data:

<item>A dumplist file.

A dump directory dumpdir

Spool directories.
</item>


<sec1>The Dumplist File<p>

The records in the dumplist are of the following form:

<tscreen><verb>
7F000401        IFIIIII         v:p.c.rel.linux
7F000402        IFIIIII         v:p.c.rel.nbsd
7F000403        IFIIIII         v:p.c.rel.fbsd
7F000404        IFIIIII         v:p.c.rel.win32
7F000405        IFIIIII         v:p.c.rel.dpmi
7F000406        IIIIIFI         v:s.public.net
7F000407        IFIIIII         f:u.jcl
7F00040B        IFIIIII         v:b.life
7F00040F        IIIIIFI         v:u.rb.more.space
7F000412        IFIIIII         f:ur.rvb
7F000414        IIIIIFI         ver:alpha.source
7F000415        IFIIIII         f:p.c.src
7F000416        IFIIIII         f:p.c.sysad
</verb></tscreen>

Note that volume group ids, a weekday bitvector and volume names are present.

The configuration infomation for the dump partitions used to be stored at 
the top of the ``dumplist'' file.  However, that is now an obsolete method to 
to provide dump partition information to <tt>backup</tt>. <tt>backup</tt>
now looks for dump partition configuration information in <tt>/vice/db/vicetab</tt> on the backup coordinator machine.  A sample <tt>vicetab</tt> is:

<tscreen><verb>
bcm          /backup1        backup
bcm          /backup2        backup
bcm          /backup3        backup
</verb></tscreen>

The first column is the name of the backup coordinator machine, the second 
column specifies the name(s) of the spool directory where the dump files
are stored.

The dump directory is assumed to be <tt>/backup</tt> and is used to install 
symbolic links in the following manner:

<tt>dumpdir/date/host/groupid.volid -> spooldir/date/host-groupid.volid.</tt>

If a full dump of a volume takes place, a file <tt>dumpdir/date/FULLDUMP</tt> 
will be left as an indicator. It produces good output for further processing 
of the backups.

The thrid column in <tt>vicetab</tt> designates the spool directories for 
used to store Coda dumps. Please see <tt>vicetab(5)</tt> for more 
information on <tt>vicetab</tt>'s layout.

<sect>Dumping the Volumes<P>

The dumplist is parsed by the backup program. For eachline it consults the VRDB to find the individual replicas. For each replica,the VLDB is consulted and the server number is filled in.

A new thread is started to handle <it>WriteDump</it> requests. Another thread is created for polling servers. The main thread continues to go through the list of volumes and request cloning. The RPC responsible for cloning is: S_VolMakeBackups.  This can only be done for read write volumes. This is a fairly complicated operation described in<tt> vol-backup.cc.</tt> It can either consist of making a fresh read only clone or of modifying an existing one. This process finishes by recording the time of cloning inthe volume information in RVM.

Backup now proceeds another time through its list ov volumes and contacts servers for a dump or incremental dump if the cloning has succeeded. It writes the dumpfile and installs the symbolic link in the backup/host directory. For incremental dumps the server uses files in the <tt>/vice/backup</tt> directory named <it>ancient</it> listing previously dumped nvodes.



*******



As the dump proceeds through the vnode lists, it writes out a <tt>7f0003f3.e20000a8.newlist</tt> file to record the VV at the moment that the volume was dumped.

Doing an incremental dump proceeds by comparing the vvlist found in the ancient file with that in RVM, and dumping Vnodes and marking them for deletion as appropriate. A smartftp RPC call is made to the backup program to dump the volume.

Finally, the server is asked to mark the volume as ancient. This is handled by <tt>S_VolMarkAsAncient</tt> and simply moves the "*.newlist" file to the "*.ancient" file.

Another try is made to get missed dumps before existing.

The program now prints the results of its actions. If a genuine full dump took place (i.e. a full dump which is not the consequence of the creation of a new volume) then a FULLDUMP file will be left behind.



<sect>The Backup.sh Script<P>

There was verymessy interaction between the<tt> backup.cc</tt> program and the <tt>backup.sh</tt> and <tt>writetotape</tt> shell scripts. The<tt> backup.sh</tt> script has been eliminated by letting<tt> backup.cc</tt> create its dumpdir and asking the tape program to copy the databases and clean up after itself.

<sect>Spooling to Tape<P>

The spooling to tape does the following:

<item>copy all relevant databases to the <tt>dumpdir.</tt>
dump <tt>dumpdir</tt> and all <tt>spooldirs</tt> to the tape.
verify the tape.
email logs.
</item>


Unfortunately, the program is mostly involved in notifying operators, waiting and testing to see if tapes have been loaded and verifying that the correct tape was loaded.

<sect>Tape Management<P>
Two levels of dumps happen: FULL dumps and Incremental dumps. Incremental tapes are labeled as <tt>Coda I WEEKDAY</tt>, and are recycled weekly. Full dumps are labeled as: <tt>CODA F tapenumber date</tt> and are never recycled.

The new scheme will write a <it>dump</it> format file to tape for the dump directory and each of the spool directories. The log will contain sufficient information to locate the correct dumpfile for a given volume.

<sect>Improvements<P>
<sect1> Features<P>
Currently the backup system is so primitive that it will deter people from using COda for two reasons. First an unreasonable amount of spooling space is needed. Secondly, too many tapes are to be retained. This needs to be addressed urgently, but it is easy!

<item> Spooling is vital. Currently the backup server needs a lot of disk space to hold all the volumes.

Multilevel backups are important.
</item>
Both are easy toimplement. Spooling is perhaps best controlled by the backup program invoking the tape program each time it has filled its spooling areas. It is already fully aware of available space int he partitions.

Since explicit text files record the vv information at the time of dumping the read only clones, it will be straight forward tolabel such files with a dump level.

<sect>Understanding<P>
The Coda backup system hands the final stage of the backup to the user by reating a read only volume. This is definitely a bonus. However, many volumes might be filled with 1000's, of files automatically and we do need to understand what "restoration" really is.

Secondly the BSD Unix dump program gets away making dumps by merely recording the dates of previous sups (a date for each level). The role of text files with version vector information for each vnode needs understanding.


</article>